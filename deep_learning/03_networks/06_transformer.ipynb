{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62e1bffc-24cd-491e-8a41-b2d6e5e995d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import random\n",
    "from tqdm import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100405b4-0f42-432a-b370-13819ca11ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['pi:', 'ti:', 'i:', 'zed', 'ei', 'kju:'],\n",
       "  ['eitʃ', 'dʌblju:', 'ju:', 'si:', 'eks', 'kju:']],\n",
       " [['p', 't', 'h', 'z', 'a', 'q'], ['h', 'w', 'u', 'c', 'x', 'q']])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集生成\n",
    "soundmark = ['ei', 'bi:', 'si:', 'di:', 'i:', 'ef', 'dʒi:', 'eitʃ', 'ai', 'dʒei', 'kei', 'el', 'em',\n",
    "             'en', 'əʊ', 'pi:', 'kju:', 'ɑː', 'es', 'ti:', 'ju:', 'vi:', 'dʌblju:', 'eks', 'wai', 'zed']\n",
    "\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q',\n",
    "            'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "t = 10000  # 总条数\n",
    "r = 0.9  # 拟动项\n",
    "seq_len = 6\n",
    "src_tokens, tgt_tokens = [], []  # 原始序列、目标序列列表\n",
    "\n",
    "for i in range(t):\n",
    "    src, tgt = [], []\n",
    "    for j in range(seq_len):\n",
    "        ind = random.randint(0, 25)\n",
    "        src.append(soundmark[ind])\n",
    "        if random.random() < r:\n",
    "            tgt.append(alphabet[ind])\n",
    "        else:\n",
    "            tgt.append(alphabet[random.randint(0, 25)])\n",
    "    src_tokens.append(src)\n",
    "    tgt_tokens.append(tgt)\n",
    "\n",
    "src_tokens[:2], tgt_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c346c82-0fda-4202-81ab-ea9d1fc96ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#实例化source和target词表\n",
    "src_vocab, tgt_vocab = Vocab(src_tokens), Vocab(tgt_tokens)\n",
    "src_vocab_size = len(src_vocab)  # 源语言词表大小\n",
    "tgt_vocab_size = len(tgt_vocab)  # 目标语言词表大小\n",
    "\n",
    "#增加开始标识<bos>和结束标识<eos>\n",
    "encoder_input = torch.tensor([src_vocab[line + ['<pad>']] for line in src_tokens])\n",
    "decoder_input = torch.tensor([src_vocab[['<bos>'] + line] for line in src_tokens])\n",
    "decoder_output = torch.tensor([tgt_vocab[line + ['<eos>']] for line in tgt_tokens])\n",
    "\n",
    "# 训练集和测试集比例8比2，batch_size = 16\n",
    "train_size = int(len(encoder_input) * 0.8)\n",
    "test_size = len(encoder_input) - train_size\n",
    "batch_size = 16\n",
    "\n",
    "# 自定义数据集函数\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, enc_inputs, dec_inputs, dec_outputs):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.enc_inputs = enc_inputs\n",
    "        self.dec_inputs = dec_inputs\n",
    "        self.dec_outputs = dec_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b90f53f-5339-43fa-956f-a236c74db84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集和测试集比例8比2\n",
    "train_size = int(len(encoder_input) * 0.8)\n",
    "test_size = len(encoder_input) - train_size\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7af189e-9bdf-4305-9046-88fe628893e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集函数\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, enc_inputs, dec_inputs, dec_outputs):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.enc_inputs = enc_inputs\n",
    "        self.dec_inputs = dec_inputs\n",
    "        self.dec_outputs = dec_outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.enc_inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]\n",
    "\n",
    "train_loader = DataLoader(MyDataSet(encoder_input[:train_size], decoder_input[:train_size], decoder_output[:train_size]), batch_size=batch_size)\n",
    "test_loader = DataLoader(MyDataSet(encoder_input[-test_size:], decoder_input[-test_size:], decoder_output[-test_size:]), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df297b53-a884-48ee-a75a-df90bcb9fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # 偶数位使用正弦函数\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # 奇数位使用余弦函数\n",
    "    return torch.FloatTensor(sinusoid_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87537c58-98fe-48bc-b40b-b881c8a2dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
      "          1.0366e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
      "          2.0733e-04,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 9.5638e-01, -2.9214e-01,  7.9142e-01,  ...,  1.0000e+00,\n",
      "          2.7989e-03,  1.0000e+00],\n",
      "        [ 2.7091e-01, -9.6261e-01,  9.5325e-01,  ...,  1.0000e+00,\n",
      "          2.9026e-03,  1.0000e+00],\n",
      "        [-6.6363e-01, -7.4806e-01,  2.9471e-01,  ...,  1.0000e+00,\n",
      "          3.0062e-03,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(get_sinusoid_encoding_table(30, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22f8cd49-61fa-486a-96f1-c695b5468325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask掩没有意义的占位符\n",
    "def get_attn_pad_mask(seq_q, seq_k):  # seq_q: [batch_size, seq_len], seq_k: [batch_size, seq_len]\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # 判断 输入那些含有P(=0),用1标记 , [batch_size, 1, len_k]\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)\n",
    "\n",
    "# mask掩未来信息\n",
    "def get_attn_subsequence_mask(seq):  # seq: [batch_size, tgt_len]\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1)  # 生成上三角矩阵,[batch_size, tgt_len, tgt_len]\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte().to(seq.device)  # [batch_size, tgt_len, tgt_len]\n",
    "    return subsequence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b0cb0f3-5d31-4e6f-8420-4bc9946a50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缩放点积注意力计算\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        '''\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size, n_heads, len_q, len_k]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V) # [batch_size, n_heads, len_q, d_v]\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e6b0233-ab1d-4e35-b5a5-dc0f3e726390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "        self.layer_norm = nn.LayerNorm(d_model) \n",
    "        \n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        '''\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)  # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)  # K: [batch_size, n_heads, len_k, d_k]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc(context) # [batch_size, len_q, d_model]\n",
    "        return self.layer_norm(output + residual), attn  # 使用类的 layer_norm 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b9d5ff7-0ad7-4580-9164-7c2866b79c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False))\n",
    "        self.layer_norm = nn.LayerNorm(d_model) \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # inputs: [batch_size, seq_len, d_model]\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return self.layer_norm(output + residual)  # 残差 + LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4751f15-4eb4-4f55-a400-93f4437854b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码器层\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()  # 多头注意力\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()  # 前馈网络\n",
    "    \n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        '''\n",
    "        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)  # enc_inputs\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)  # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f11c6a7-95d4-4828-8e28-3d694ee11252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码器模块\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(src_vocab_size, d_model), freeze=True)\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "    \n",
    "    def forward(self, enc_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        '''\n",
    "        word_emb = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "        pos_emb = self.pos_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "        enc_outputs = word_emb + pos_emb\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3e068cb-3351-4aeb-ac18-00704ea77570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解码器层\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.dec_enc_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        '''\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs) # [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e2a8ecb-e5fd-462a-a987-35d3ad8e50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(tgt_vocab_size, d_model), freeze=True)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        enc_intpus: [batch_size, src_len]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        '''\n",
    "        word_emb = self.tgt_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n",
    "        pos_emb = self.pos_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = word_emb + pos_emb\n",
    "        dec_self_attn_(pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs) # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequence_mask(dec_inputs) # [batch_size, tgt_len]\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0) # [batch_size, tgt_len, tgt_len]\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs) # [batc_size, tgt_len, src_len]\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d04a7286-040a-4559-a58f-1654cb048ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False)\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        '''\n",
    "        # tensor to store decoder outputs\n",
    "        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "        # dec_outpus: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f636ad6f-a0ee-46cc-b1f2-9e022ee25ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512  # 字 Embedding 的维度\n",
    "d_ff = 2048  # 前向传播隐藏层维度\n",
    "d_k = d_v = 64  # K(=Q), V的维度\n",
    "n_layers = 6  # 有多少个encoder和decoder\n",
    "n_heads = 8  # Multi-Head Attention设置为8\n",
    "num_epochs = 50  # 训练50轮\n",
    "# 记录损失变化\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d570a1b-f854-46e9-809f-c915b6902f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = Transformer().to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # 很神奇，这里Adam的效果不如SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00f89b9c-9756-428d-ba04-8a1e2e53baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7f4d4ab-a7fb-453e-9928-d99efa59a2f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 1/100 [00:02<03:56,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss = 0.226114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                          | 2/100 [00:04<03:56,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 loss = 0.183462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                         | 3/100 [00:07<03:54,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 loss = 0.179684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                         | 4/100 [00:09<03:51,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 loss = 0.184136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                        | 5/100 [00:12<03:49,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 loss = 0.175499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                        | 6/100 [00:14<03:46,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 loss = 0.171184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███                                        | 7/100 [00:16<03:44,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 loss = 0.185450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▍                                       | 8/100 [00:19<03:43,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 loss = 0.199930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▊                                       | 9/100 [00:21<03:40,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 loss = 0.166021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 10/100 [00:24<03:37,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 loss = 0.161740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▌                                     | 11/100 [00:26<03:35,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 loss = 0.167937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████                                     | 12/100 [00:28<03:32,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 loss = 0.160571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▍                                    | 13/100 [00:31<03:29,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 loss = 0.148604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▉                                    | 14/100 [00:33<03:27,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 loss = 0.134637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▎                                   | 15/100 [00:36<03:25,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 loss = 0.137503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▋                                   | 16/100 [00:38<03:22,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 loss = 0.152504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▏                                  | 17/100 [00:41<03:20,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 loss = 0.149871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▌                                  | 18/100 [00:43<03:17,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 loss = 0.143216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▉                                  | 19/100 [00:45<03:15,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 loss = 0.131700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▍                                 | 20/100 [00:48<03:12,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 loss = 0.146156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▊                                 | 21/100 [00:50<03:10,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 loss = 0.133912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████▏                                | 22/100 [00:53<03:08,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 loss = 0.173233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▋                                | 23/100 [00:55<03:05,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 loss = 0.174097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████                                | 24/100 [00:57<03:03,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 loss = 0.130198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▌                               | 25/100 [01:00<03:03,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 loss = 0.151560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▉                               | 26/100 [01:02<03:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 loss = 0.136236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▎                              | 27/100 [01:05<02:59,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 loss = 0.130024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▊                              | 28/100 [01:07<02:58,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 loss = 0.155479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▏                             | 29/100 [01:10<02:55,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 loss = 0.142666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▌                             | 30/100 [01:12<02:53,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 loss = 0.120232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████                             | 31/100 [01:15<02:49,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 loss = 0.110663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▍                            | 32/100 [01:17<02:46,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 loss = 0.120504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▊                            | 33/100 [01:20<02:44,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 loss = 0.137724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████▎                           | 34/100 [01:22<02:41,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 loss = 0.134728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▋                           | 35/100 [01:25<02:40,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 loss = 0.109112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████                           | 36/100 [01:27<02:36,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 loss = 0.158930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████▌                          | 37/100 [01:30<02:34,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 loss = 0.104080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████▉                          | 38/100 [01:32<02:31,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 loss = 0.105628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████▍                         | 39/100 [01:34<02:28,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 loss = 0.130482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▊                         | 40/100 [01:37<02:26,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 loss = 0.114571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▊                         | 40/100 [01:39<02:29,  2.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 15\u001b[0m     loss_history\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for enc_inputs, dec_inputs, dec_outputs in train_loader:\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        dec_outputs: [batch_size, tgt_len]\n",
    "        '''\n",
    "        enc_inputs, dec_inputs, dec_outputs = enc_inputs.to(device), dec_inputs.to(device), dec_outputs.to(device)\n",
    "        # outputs: [batch_size * tgt_len, tgt_vocab_size]\n",
    "        outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "        loss = criterion(outputs, dec_outputs.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(loss.item())\n",
    "    print('Epoch:', '%d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd86d4c6-95b6-410f-8da8-5ac177cbe989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "translation_results = []\n",
    "\n",
    "correct = 0\n",
    "error = 0\n",
    "\n",
    "for enc_inputs, dec_inputs, dec_outputs in test_loader:\n",
    "    '''\n",
    "    enc_inputs: [batch_size, src_len]\n",
    "    dec_inputs: [batch_size, tgt_len]\n",
    "    dec_outputs: [batch_size, tgt_len]\n",
    "    '''\n",
    "    enc_inputs, dec_inputs, dec_outputs = enc_inputs.to(device), dec_inputs.to(device), dec_outputs.to(device)\n",
    "    # outputs: [batch_size * tgt_len, tgt_vocab_size]\n",
    "    outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "    # pred形状为 (seq_len, batch_size, vocab_size) = (1, 1, vocab_size)\n",
    "    # dec_outputs, dec_self_attns, dec_enc_attns = model.decoder(dec_inputs, enc_inputs, enc_output)\n",
    "\n",
    "    outputs = outputs.squeeze()\n",
    "\n",
    "    pred_seq = []\n",
    "    for output in outputs:\n",
    "        next_token_index = output.argmax().item()\n",
    "        if next_token_index == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        pred_seq.append(next_token_index)\n",
    "\n",
    "    pred_seq = tgt_vocab[pred_seq]\n",
    "    tgt_seq = dec_outputs.squeeze().tolist()\n",
    "\n",
    "    # 需要注意在<eos>之前截断\n",
    "    if tgt_vocab['<eos>'] in tgt_seq:\n",
    "        eos_idx = tgt_seq.index(tgt_vocab['<eos>'])\n",
    "        tgt_seq = tgt_vocab[tgt_seq[:eos_idx]]\n",
    "    else:\n",
    "        tgt_seq = tgt_vocab[tgt_seq]\n",
    "    translation_results.append((' '.join(tgt_seq), ' '.join(pred_seq)))\n",
    "\n",
    "    for i in range(len(tgt_seq)):\n",
    "        if i >= len(pred_seq) or pred_seq[i] != tgt_seq[i]:\n",
    "            error += 1\n",
    "        else:\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "067a1fd6-24c8-4326-b4a0-db0a8b30b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48633333333333334\n"
     ]
    }
   ],
   "source": [
    "print(correct/(correct+error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2e3b4fb-e2d0-4db3-b151-babbe2c84ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('j k y r n w', 'j y w w w w'),\n",
       " ('e u d m k i', 'e d k m k i'),\n",
       " ('f e l v g d', 'f e o o o o'),\n",
       " ('n g j a f z', 'n j j a f z f'),\n",
       " ('t h e t t l', 't h s s h'),\n",
       " ('g k r y z t', 'x k z y t t'),\n",
       " ('g j b x f p', 'g x p x f p'),\n",
       " ('x a i z k a', 'x a z a a a'),\n",
       " ('w w f w o f', 'w f f e f f f'),\n",
       " ('k n r o k r', 'k o r o k r'),\n",
       " ('f n u q v q', 'f o o o q q'),\n",
       " ('k p c v l t', 'k t t t l t'),\n",
       " ('n d u a h s', 'n s s s s s'),\n",
       " ('l k j y l l', 's j y l l'),\n",
       " ('y z e v a i', 'y v v i i i'),\n",
       " ('s h r h x f', 's h x f f f'),\n",
       " ('z t n b b i', 'z b b b i i b'),\n",
       " ('q z z j b d', 'q b d d b d'),\n",
       " ('a s g n d i', 'a s i n d a'),\n",
       " ('x v a w l h', 'x a a h h h x'),\n",
       " ('b n s r b r', 'b n r b b b'),\n",
       " ('l a g e g g', 'l g g e g g g'),\n",
       " ('p q w i g g', 'p v i i g g'),\n",
       " ('s q l y t g', 's q g y g g'),\n",
       " ('u s t f v y', 'u f v v v y u'),\n",
       " ('s p x j q m', 's x j j q'),\n",
       " ('g x r u g y', 'p u y u y y'),\n",
       " ('o o k i l a', 'o k k l w w'),\n",
       " ('d n a b w g', 'd a a w w g'),\n",
       " ('m i n y b r', 'm i u y b h'),\n",
       " ('p x j z f h', 'p q j f f h'),\n",
       " ('c u j v m v', 'c u f m m v'),\n",
       " ('a y l o s s', 'a o o s s s s'),\n",
       " ('b l x s a w', 'b a a a a w'),\n",
       " ('q v s p f o', 'v m x o o o f'),\n",
       " ('o j p a b e', 'o n e a e e'),\n",
       " ('q h s l n r', 'q h n n v v'),\n",
       " ('r n n s r m', 'r s m m m m'),\n",
       " ('u o t p x f', 'u o p x x f'),\n",
       " ('h e v k o b', 'x a o o o b'),\n",
       " ('b i c q h l', 'b e h h h l'),\n",
       " ('o i c j s n', 'x i c k s k'),\n",
       " ('o t m b j w', 'o t m j j w'),\n",
       " ('z c r u q t', 'z a t a t t'),\n",
       " ('r x g o v i', 'r i i i i i'),\n",
       " ('y y g x l t', 'y x x l l y'),\n",
       " ('w i f r d v', 'w i r v v f'),\n",
       " ('e f m l d q', 'e q l l q q'),\n",
       " ('r i k k n v', 'r n n n n e'),\n",
       " ('d c p k r o', 'd u o o o o'),\n",
       " ('k j x w x s', 'k j x x x s'),\n",
       " ('a p u y n i', 'a u u i n i'),\n",
       " ('i x l n q m', 'i x l q m m'),\n",
       " ('n u h c p v', 'n s p v v v'),\n",
       " ('p m x w l p', 'p x x l p p'),\n",
       " ('x a j a a s', 'x a a a a s a'),\n",
       " ('g s r g d t', 'g s r d d u'),\n",
       " ('k x r e x f', 'k x x x f x x'),\n",
       " ('f h h d s b', 'f b s d b b'),\n",
       " ('y w m p x b', 'y w n b x b'),\n",
       " ('a e a p u b', 'a k b u b b'),\n",
       " ('y r r y v j', 'y v j j j j'),\n",
       " ('o m c c j x', 'o x c x x x x'),\n",
       " ('b t j k l m', 'b k k k l m'),\n",
       " ('u k m v k p', 'u m p v p p'),\n",
       " ('j a n k h w', 'j k k k k k'),\n",
       " ('m g v u w o', 'm v u u w v'),\n",
       " ('t z n h l u', 't h u h l u'),\n",
       " ('u m z w h a', 'u h a a h a'),\n",
       " ('c c j y a f', 'c f f a a f'),\n",
       " ('k t h v i u', 'k t i i u u'),\n",
       " ('n g b t e s', 'n e s t e s'),\n",
       " ('k b o u o e', 'k o o u e e'),\n",
       " ('h f i z o m', 'h f i o o m'),\n",
       " ('p q y h g s', 'p y y h g s'),\n",
       " ('e y s c z t', 'e y s t t t'),\n",
       " ('g s r u z s', 'g s u u s s'),\n",
       " ('v i z g h d', 'v i z g d d'),\n",
       " ('x g f m a d', 'x f f d d d a'),\n",
       " ('c j b b u h', 'a b b u u h'),\n",
       " ('u c t d q p', 'u c v p p p'),\n",
       " ('j j j r g x', 'j l l l l x l'),\n",
       " ('k t d g y w', 'k t d w w w'),\n",
       " ('a n e k r p', 'c p p p p p'),\n",
       " ('d q q x q d', 'd d d d d d'),\n",
       " ('v d k s v v', 'v s s s v k'),\n",
       " ('g h n d c h', 'g h d d c h'),\n",
       " ('z r v y y h', 'z h y y h h'),\n",
       " ('x k i n t m', 'x i m t t m'),\n",
       " ('n b o r o w', 'n w w w t w'),\n",
       " ('t z m o v n', 't o x o n n'),\n",
       " ('m c i p c n', 'm c i p c n'),\n",
       " ('a u x i x q', 'a x x q q q'),\n",
       " ('i z q p r h', 'i h f h r v'),\n",
       " ('m s t n u w', 'k t u w u w'),\n",
       " ('y t o y s x', 'y y x x x x'),\n",
       " ('o d r r b l', 'i l b b b f'),\n",
       " ('v m g n x y', 'v m x n y y'),\n",
       " ('f s n c b r', 'f a a a a r'),\n",
       " ('e u j u t p', 'e u j p t p'),\n",
       " ('k i w o i h', 'p i o h h h'),\n",
       " ('c v z y z a', 'c a y a a a'),\n",
       " ('k r o s b r', 'k o b b b'),\n",
       " ('t s y p m p', 't p y p p p'),\n",
       " ('c q m e i v', 'c x x x x x'),\n",
       " ('l y k t n j', 'l n i n n j'),\n",
       " ('v l u k b k', 'v l k k b k'),\n",
       " ('z y z x s y', 'f x x x x y'),\n",
       " ('f w m c o m', 'f k k o o m'),\n",
       " ('a k d o e o', 'a o d o o o'),\n",
       " ('a w m c d h', 'a m m h h h'),\n",
       " ('g c q a n t', 'g h t n t t'),\n",
       " ('w u z w d f', 'w f w f d f'),\n",
       " ('j t c f x y', 'j x x x x y'),\n",
       " ('o t p f j f', 'o j f f f f'),\n",
       " ('r u g z k m', 'r k p k u u'),\n",
       " ('t t m b b s', 't l l s l s'),\n",
       " ('h e v e b o', 'h e o o o o'),\n",
       " ('l d t k z w', 'l h z w z w'),\n",
       " ('a v v j o j', 'a o o o o p j'),\n",
       " ('f d a e a o', 'f a a e a o a'),\n",
       " ('g v q t v v', 'g q q v v v'),\n",
       " ('l j z z l q', 'l j z z q q'),\n",
       " ('o k m k w o', 'o k m z d'),\n",
       " ('d h w j p j', 'd j j j p j'),\n",
       " ('x z s d q a', 'x a s o a a'),\n",
       " ('f v d v k i', 'f v d i i i'),\n",
       " ('p v h z x k', 'f x x x x k'),\n",
       " ('n d u l u x', 'n x x l x x'),\n",
       " ('m l s o l g', 'm o o o x o'),\n",
       " ('v s n c g i', 'y s g g i i'),\n",
       " ('x y i a s z', 'x a z a z z'),\n",
       " ('n z g j y n', 'n j j j y n'),\n",
       " ('x p m l c z', 'x u z z z z'),\n",
       " ('s y f u o u', 's o u w u u'),\n",
       " ('b s d y h u', 'b h d h u u'),\n",
       " ('o v d w g x', 'r d x x g x'),\n",
       " ('l q a v t h', 'l a h h h h'),\n",
       " ('t e p f w b', 't p f b w b'),\n",
       " ('t f g c c g', 't j g c c m'),\n",
       " ('t z q u t s', 'd n u u n n'),\n",
       " ('w c u z v r', 'e c r v v r'),\n",
       " ('z v t x y n', 'z n t x n n'),\n",
       " ('s x s j k q', 'd j a j a q'),\n",
       " ('l o o z i x', 'l o x x x x'),\n",
       " ('l v c i p l', 'o v p p p l'),\n",
       " ('x x z o f z', 'x o o f f x x'),\n",
       " ('p h o f o z', 'p h o o z z'),\n",
       " ('a x r k v n', 'a x n j n n'),\n",
       " ('t o a d w j', 'j d a w w j'),\n",
       " ('c p z b f h', 'c p h h f f'),\n",
       " ('j a d e x m', 'j x e x m m'),\n",
       " ('c q i c o j', 'c o o o o j'),\n",
       " ('g i t j g m', 'i m m m m m'),\n",
       " ('z j a h f g', 'z f y f f g'),\n",
       " ('w r p d e b', 'w v p v b b'),\n",
       " ('n q d y c p', 'n p p p p p'),\n",
       " ('p d s u o b', 'p d b o o b'),\n",
       " ('d h d o l m', 'd m o m m m'),\n",
       " ('q v e v q h', 'e v q q q h'),\n",
       " ('v c u i o d', 'v i u o d d'),\n",
       " ('l h p c x s', 'l x x x x s'),\n",
       " ('w o g r o x', 'w o j r x x'),\n",
       " ('s z c m m r', 's m m m m s s'),\n",
       " ('n n z h l d', 'n n n d l d n'),\n",
       " ('r v i q k x', 'r i i k x x'),\n",
       " ('d r y c o m', 'd m o o o m'),\n",
       " ('i c l f i s', 'i l f i i i'),\n",
       " ('e i a y n p', 'e i y p p p'),\n",
       " ('w r n c z y', 'w y y z z w'),\n",
       " ('r u y o t m', 'r o y a a a'),\n",
       " ('r m g u p u', 'r p p p p u'),\n",
       " ('u d c y f p', 'u y f f p p'),\n",
       " ('j v r u y z', 'j u r z z z'),\n",
       " ('s m d q j u', 's u u j j u'),\n",
       " ('p c j y c h', 'p j j y c p'),\n",
       " ('f q z q m a', 'f m b a a a'),\n",
       " ('r b k c q h', 'i k k c h i'),\n",
       " ('h f x c z d', 'h d t d d d'),\n",
       " ('j l k g q a', 'j k q q a a'),\n",
       " ('i w m n l s', 'i f m f f f'),\n",
       " ('n y i m c r', 'f i i c c w'),\n",
       " ('o h t h v o', 'o h t v o o'),\n",
       " ('k b n z e v', 'k b e e e v'),\n",
       " ('i q u m j j', 'i j u j j j j'),\n",
       " ('k u g w w q', 'k u w w w q'),\n",
       " ('n d h i b v', 'n h h v v v'),\n",
       " ('h r s q c n', 'h s s q q q'),\n",
       " ('f a v l w x', 'f a x w x x'),\n",
       " ('o s r k t g', 'o t o g g x'),\n",
       " ('d a q v r e', 'd u q e e e'),\n",
       " ('a n h v t y', 'a v y y y y'),\n",
       " ('o u z x x z', 'o x x x x z'),\n",
       " ('l b s w l o', 'l o x o o o'),\n",
       " ('m j a c p z', 'y a a c c z'),\n",
       " ('q d d y x u', 'q u u u u u'),\n",
       " ('i k a f t t', 'i a p t t t'),\n",
       " ('v e x z m x', 'v x x x x x'),\n",
       " ('s l g b n o', 's o o o o s'),\n",
       " ('u t y i m x', 'u x x x x x'),\n",
       " ('z q a e s j', 'j a r v r j'),\n",
       " ('q g h o g q', 'q o o o q q'),\n",
       " ('u f d b l d', 'u d d b l d'),\n",
       " ('c o s a h w', 'c a a a w w'),\n",
       " ('v d y t w c', 'p d w c c c'),\n",
       " ('p f b a d v', 'p d d d d f'),\n",
       " ('y f k v q p', 'y p p p p p'),\n",
       " ('k a i y k g', 'k i i g k g'),\n",
       " ('y b f b u y', 'd u u u u y'),\n",
       " ('y b t k g k', 'y k k k k k'),\n",
       " ('w e c y d r', 'w e j d d r'),\n",
       " ('d q w x y q', 'd y y x y q'),\n",
       " ('f x z h p j', 'f j j j p j'),\n",
       " ('u f r f k p', 'u f f f k p'),\n",
       " ('x g x y a p', 'x p p p p p'),\n",
       " ('f r m x l n', 'f x b l b b'),\n",
       " ('f y y j n u', 'c y u u u u'),\n",
       " ('g f q h v l', 'g w q l v l'),\n",
       " ('j f a i y j', 'i i y y u j'),\n",
       " ('f s g k u a', 'f j g a a a'),\n",
       " ('c l s y y v', 'c v y y v v'),\n",
       " ('d l u h h m', 'd u e e m m'),\n",
       " ('x v t e t t', 'x x x e x t'),\n",
       " ('i f y n h g', 'i v g n g g'),\n",
       " ('f q e m s w', 'f j j u j u'),\n",
       " ('r k n h a o', 'v o o o a o'),\n",
       " ('i n i q x m', 'i i x m x m'),\n",
       " ('q w c q a u', 'q a a u a u'),\n",
       " ('r b p w p c', 'r p p p p p w'),\n",
       " ('n n e u w t', 'n w w a w w'),\n",
       " ('j r z z h p', 'j p p p p p'),\n",
       " ('n z x l r r', 'n a r r r r f'),\n",
       " ('i s s i d j', 'i s j j i j i'),\n",
       " ('m s x g t q', 'm t t t t y'),\n",
       " ('w k c o s c', 'w c c s s c'),\n",
       " ('q i y a z l', 'q i e e e l'),\n",
       " ('q q y k c h', 'q k k k z h'),\n",
       " ('f i l i a j', 'f j a a a m'),\n",
       " ('v w e j f h', 'v f e h h h'),\n",
       " ('h a w k y o', 'h j j j j o'),\n",
       " ('u n q f w w', 'u n f s s w'),\n",
       " ('u a j f t t', 'u i t t t t'),\n",
       " ('n z e i e o', 'n i e o o o'),\n",
       " ('c w j q p a', 'c j p p a a p'),\n",
       " ('l t l s l y', 'l y l l l y'),\n",
       " ('i e q i l s', 'i i i l l s'),\n",
       " ('e h h l q s', 'i l s q q s'),\n",
       " ('o d h k z o', 'o o r o o o'),\n",
       " ('o b l y f j', 'o n j j j j'),\n",
       " ('b s d t v x', 'b t x t x x'),\n",
       " ('a z v y z u', 'a y y y y y'),\n",
       " ('i j d x s e', 'i j d x e e'),\n",
       " ('c l a d m x', 'w a m m m x'),\n",
       " ('s q q t d b', 's q q s b b b'),\n",
       " ('d s f l o a', 'd o f a a a'),\n",
       " ('u w z x e r', 'u x x x r r'),\n",
       " ('w c n j e c', 'w c e e e c'),\n",
       " ('b l p g s s', 'b p p s p p'),\n",
       " ('c r i x r q', 'c x i x t x x'),\n",
       " ('s x c v k m', 's h k m k m'),\n",
       " ('t g u x p q', 't u x x p q'),\n",
       " ('h w c y m z', 'h y y y z z'),\n",
       " ('w v n j z w', 'w n n j w w'),\n",
       " ('p l g l k p', 'p p k k p p'),\n",
       " ('p y y k p o', 'y y y y g y y'),\n",
       " ('b x e m b z', 'b x m m z z'),\n",
       " ('o r a a a l', 'o a a a a a a'),\n",
       " ('h v m b i n', 'h n l x i n'),\n",
       " ('o c k c x k', 'o i i i x k'),\n",
       " ('b l f n f s', 'b f f f s s'),\n",
       " ('j k g w d e', 'j w w w e e'),\n",
       " ('q m i d z d', 'q m z v d d'),\n",
       " ('q g q i w d', 'q i w w w d'),\n",
       " ('t f n v p r', 't p p p p u'),\n",
       " ('v a h k t r', 'a a a a r a a'),\n",
       " ('t w e b c a', 't a a c a a'),\n",
       " ('x y i f v t', 'x f f f x x'),\n",
       " ('a f h j i t', 'a h i t i t i'),\n",
       " ('o n c r b l', 'o n b r b f'),\n",
       " ('q n f v u k', 'q f k k u k'),\n",
       " ('s r p k t g', 's t p k g g'),\n",
       " ('d a f g l n', 't g f g n n'),\n",
       " ('x j n d d g', 'x i i i d g'),\n",
       " ('x a l s x e', 'x a f s x x'),\n",
       " ('z x f a v i', 'z i i l i i'),\n",
       " ('l f t t b v', 'l t t b b l'),\n",
       " ('y k o k c h', 'y c c c c h'),\n",
       " ('z w z o l p', 'z n n n n n'),\n",
       " ('k h r r h b', 'k b b b b b'),\n",
       " ('l q x k f i', 'l i i i i i'),\n",
       " ('p h s k v q', 'i s q k v q'),\n",
       " ('j o a c c v', 'j c c c c v'),\n",
       " ('y p h h m a', 'y e h a a a'),\n",
       " ('s t v t g u', 's u u u u u'),\n",
       " ('b u d m c x', 'b x d c x x'),\n",
       " ('f f u v b r', 'f r r r b u f'),\n",
       " ('w j y m b k', 'w x b k k k'),\n",
       " ('j x k i f y', 'j i i i y y'),\n",
       " ('s w s u q x', 's s s s x s s'),\n",
       " ('o q u o u o', 'o u u o o o o'),\n",
       " ('o x l d i t', 'x i i i i t'),\n",
       " ('u h k v g n', 'u g g n g n'),\n",
       " ('t k d o l n', 't k j n n n'),\n",
       " ('y g d i j f', 'y f c f f f'),\n",
       " ('b u f z u w', 'b w f f f w'),\n",
       " ('d j o f b o', 'd o o o o o'),\n",
       " ('d w z z w o', 'q b b o w o'),\n",
       " ('s s z g i m', 's i i i i m s'),\n",
       " ('z u f y v m', 'z m m m m m x'),\n",
       " ('q c o q n z', 'x o d d d d'),\n",
       " ('g m c z u a', 'i z z z u a'),\n",
       " ('i o n q l x', 'i x x x l x'),\n",
       " ('x f p b j q', 'x j b b q q'),\n",
       " ('m s h s b r', 'm s h b b f'),\n",
       " ('r t l j v a', 'r a w a a a'),\n",
       " ('y v e p m p', 'y m c p p p'),\n",
       " ('c j y x e u', 'd j u u u u'),\n",
       " ('u m j b x c', 'u b x d x d'),\n",
       " ('a o v f s c', 'a s s s s c'),\n",
       " ('r m u z e d', 'j d e e e d'),\n",
       " ('f d m n t h', 'f d t t t h'),\n",
       " ('b i g v e z', 'a g g z z z'),\n",
       " ('e h v i i q', 'e u u i q q'),\n",
       " ('d i b g g k', 'f v b v k k'),\n",
       " ('k c q d n v', 'k d d n v v'),\n",
       " ('v b o k y p', 'v p y y p p'),\n",
       " ('h y z k d y', 'h y y y d y'),\n",
       " ('e a s o r y', 'e s y o y y'),\n",
       " ('h u y q y o', 'h o y o o o'),\n",
       " ('j x m b m e', 'j k k k k e'),\n",
       " ('r z e a v w', 'r e a a v w'),\n",
       " ('e s v l m n', 'e z z z z n'),\n",
       " ('d q l t e h', 'd t t e h h'),\n",
       " ('e f f w o a', 'e f w w a a'),\n",
       " ('r n x h e s', 'a x s h s s'),\n",
       " ('i y u n p u', 'i u u p p u'),\n",
       " ('w y i p q y', 'w y y p y y'),\n",
       " ('y l v w v x', 'y v v x x x w'),\n",
       " ('l l e s y y', 'l y y y y y'),\n",
       " ('m i u b z z', 'm i b z z'),\n",
       " ('d a i t a h', 'd a h t h h'),\n",
       " ('v v g l j d', 't d l d d d'),\n",
       " ('v q t u z w', 'v f u u z w'),\n",
       " ('c z l y g h', 'c z x x x x'),\n",
       " ('d l r o h j', 'd h j j j j'),\n",
       " ('m f m y s m', 'f s y s s m'),\n",
       " ('f g j m n l', 'f j m m l l'),\n",
       " ('v p q l v v', 'd z l v v v'),\n",
       " ('h b u x c l', 'h u c l c l'),\n",
       " ('n n c i r k', 'n k k i k k'),\n",
       " ('e y d t h h', 'e d h h h h'),\n",
       " ('q s c r h h', 'q h h r h h'),\n",
       " ('t b t r i d', 'p i t i i d'),\n",
       " ('y e t s e p', 'y e p s p p'),\n",
       " ('q q p u d r', 'q u u u w r'),\n",
       " ('e t k e s a', 'n k k a s a'),\n",
       " ('j k t g l m', 'j k g a a m'),\n",
       " ('y m f i k a', 'y f i i a a'),\n",
       " ('n t a f i n', 'n f f f i n'),\n",
       " ('u n c n u u', 'u n u u u u'),\n",
       " ('c e c d i j', 'c i i i j j'),\n",
       " ('l r g q w r', 'l r w w w r'),\n",
       " ('m w j s m p', 'm p p s p p'),\n",
       " ('k e b d t t', 'k d t t t t'),\n",
       " ('e m z i e e', 'e e z o o e'),\n",
       " ('l w m r o c', 'l o c c o c'),\n",
       " ('b j z u h s', 'b j a u s s'),\n",
       " ('w y u k v b', 'w u l l l b'),\n",
       " ('g a b s v b', 'x s s s o b'),\n",
       " ('h x e s t u', 'u x s s u u'),\n",
       " ('p b t u k m', 'p u u u k m'),\n",
       " ('s d c d p y', 's p p p p e'),\n",
       " ('w k t f m g', 'w m m m m g'),\n",
       " ('r s h v x l', 'r v x v l l'),\n",
       " ('z g k y g g', 'z m m m m a'),\n",
       " ('e p z h a w', 'i h s s s s'),\n",
       " ('s b z u w z', 's b z j j z'),\n",
       " ('j g t n x g', 'j g x x x g'),\n",
       " ('e a v m r l', 'e a r r r l'),\n",
       " ('g s m l a g', 'g m l l g g'),\n",
       " ('m a q s s c', 'm s s s s s'),\n",
       " ('m l w q w j', 'm w w w j j'),\n",
       " ('a u k e r z', 'a u r r r z'),\n",
       " ('d g k u a x', 'd a a a a x'),\n",
       " ('b q x i v l', 'b q l i v l'),\n",
       " ('z e q u c a', 'z a u u c a'),\n",
       " ('k s j m d v', 'k v m m v v'),\n",
       " ('f r f v n t', 'f f v n n w'),\n",
       " ('k y t s i a', 'k i t i i a'),\n",
       " ('i b x t b c', 'i p b b b c'),\n",
       " ('y v o c d u', 'y c c u d u'),\n",
       " ('a k o y d a', 'a o o a d a'),\n",
       " ('f q h g z n', 'f b b z n n'),\n",
       " ('x q y d z v', 'x p v v p v'),\n",
       " ('f m b y o a', 'f d y y o a'),\n",
       " ('f d e q x x', 'f d e o o o'),\n",
       " ('k y y a h q', 'k y q q q q'),\n",
       " ('f v s v a x', 'f x x x x x x'),\n",
       " ('c i w a c q', 'c a a a c q'),\n",
       " ('n r x u k j', 'n x j j j j'),\n",
       " ('l s q r e j', 'l r j j j j'),\n",
       " ('l t v s b o', 'l s s s o o'),\n",
       " ('z m z b s u', 'z z u u u u'),\n",
       " ('n f f z f b', 'n f f b b b'),\n",
       " ('z i n o r e', 'z i n o w e'),\n",
       " ('v k l s k q', 'v s s s k q'),\n",
       " ('f s e e q k', 'f e e k k k'),\n",
       " ('d k o x z p', 'd p p p p p'),\n",
       " ('e o q g x p', 'e q q p p p'),\n",
       " ('e r c z t v', 'e c j m v v'),\n",
       " ('i t f x f s', 'i s f x s s i'),\n",
       " ('y d f x k r', 'y d c k e e'),\n",
       " ('r q t h t s', 'r h s h s s'),\n",
       " ('v u p e k e', 'v p e e e e'),\n",
       " ('i a i r l y', 'i u y l l y i'),\n",
       " ('y u m v t k', 'y m m v k k'),\n",
       " ('n t e p q t', 'd t p h h h'),\n",
       " ('e x r p k z', 'x x p p z z'),\n",
       " ('j q u l s t', 'j u s s s t s'),\n",
       " ('t c c m v y', 't c w w v y'),\n",
       " ('k i z s q a', 'i i a s q a'),\n",
       " ('r g f p w o', 'i v u w w o'),\n",
       " ('c n w l m z', 'c a a m m z'),\n",
       " ('m y m u g j', 'm d g g j j m'),\n",
       " ('c m q w d x', 'u d d x x x'),\n",
       " ('x y q j v n', 'x y q j v n'),\n",
       " ('z t c c d y', 'z c c d d y'),\n",
       " ('d v u f w q', 'd w w f w o'),\n",
       " ('p c v k t z', 'p z k z t z'),\n",
       " ('o m p o a m', 'o m a a a m'),\n",
       " ('z u d s g u', 'p u u i u u'),\n",
       " ('w a c p n c', 'w c c p u c'),\n",
       " ('c x a o j k', 'x a o j n n'),\n",
       " ('g r z d w v', 'g z w d w v'),\n",
       " ('d c t j p t', 'd t j j p t'),\n",
       " ('p p h d s c', 'p s s s s p'),\n",
       " ('g p e x u t', 'g p u x u'),\n",
       " ('x l n g v x', 'x x g x x x'),\n",
       " ('z y q u x u', 'z x j u j j'),\n",
       " ('q l g d s l', 'q u d s s'),\n",
       " ('y c j l o m', 'y o o m o m'),\n",
       " ('z s w j i d', 'z s i j d d'),\n",
       " ('m x s y o a', 'm y o o o a'),\n",
       " ('r d v v z n', 'r v v n n n'),\n",
       " ('t m f c s z', 't s s s s z'),\n",
       " ('d c z v d w', 'j d d d d w'),\n",
       " ('m h d f a w', 'm a f a a w'),\n",
       " ('f c a i v z', 'f z a i z z'),\n",
       " ('i r g j q y', 'i v j j y y'),\n",
       " ('o v u r y n', 'v u u y y n'),\n",
       " ('u m r d i h', 'u r k i i k'),\n",
       " ('w c e n y n', 'w e e n y n'),\n",
       " ('u c u h z z', 'u z z z z z'),\n",
       " ('e k r m m g', 'e m m m m m'),\n",
       " ('z r b u o t', 'z b b o o t'),\n",
       " ('g r c n m l', 'g n n m m l'),\n",
       " ('n f z x o z', 'n i z a a o'),\n",
       " ('u q q i k w', 'u i i k w w'),\n",
       " ('g k a n r a', 'g a a a a a'),\n",
       " ('u s v z s b', 'u h s s s b'),\n",
       " ('w f k y m l', 'q k y l l l'),\n",
       " ('v f x d i m', 'v i x i i m'),\n",
       " ('k h p b w s', 'k b s b s s'),\n",
       " ('x x r i j g', 'x j j j j j x'),\n",
       " ('d j c r n h', 'd d c h d d'),\n",
       " ('c t z g h h', 'c h h h h h'),\n",
       " ('l b e v x z', 'x x v v z z'),\n",
       " ('j e r g e b', 'j e g g g g'),\n",
       " ('b e a f q k', 'b q k k k k'),\n",
       " ('d u m k f e', 'd t f f f e'),\n",
       " ('y d j z h s', 'y j f h f f'),\n",
       " ('d t n n f f', 'a f f f f f'),\n",
       " ('b x c v o z', 'b o v v o'),\n",
       " ('g w k h r y', 'g w h r r t'),\n",
       " ('m o x p y y', 'm y y y y y'),\n",
       " ('e b y r e a', 'e y y a a a'),\n",
       " ('w h j z f z', 'w j j z f z'),\n",
       " ('b b u b w z', 'b z z b z z b'),\n",
       " ('r j r v v h', 'h h h v v h'),\n",
       " ('k p j m y o', 'k p n t n n'),\n",
       " ('g g y x b m', 'g m m m m m'),\n",
       " ('t d k i d i', 't i i i d i'),\n",
       " ('p k u p i u', 'h u u p i u'),\n",
       " ('d j g a z y', 'd j a a z y'),\n",
       " ('g b q c n v', 'g v c v v v'),\n",
       " ('w x h c w i', 'w x u u i i'),\n",
       " ('r q t i c g', 'r i i i g g'),\n",
       " ('o b w d o m', 'o d m o m m'),\n",
       " ('u k e q m a', 'u q q a a a u'),\n",
       " ('e b s z a y', 'e q q z y y'),\n",
       " ('j c d x x k', 'j d x x x k'),\n",
       " ('n u d c s f', 'n s f s f f'),\n",
       " ('v k b n j u', 'v k j j j u'),\n",
       " ('k f v x w q', 'k q w w w'),\n",
       " ('m w e d d m', 'm d d d'),\n",
       " ('c d t q a u', 'c d a a a u'),\n",
       " ('n u a e h a', 'n a a e h a'),\n",
       " ('k u w p j n', 'k u p p n n'),\n",
       " ('c a x v s x', 'a a x s s x x'),\n",
       " ('s b f w v y', 's v m w y y'),\n",
       " ('q e e u u k', 'q u u u u o'),\n",
       " ('q o c q o v', 'q o q o o o'),\n",
       " ('v b n y g m', 'v v y m m m'),\n",
       " ('t e x f v j', 't x x j j j'),\n",
       " ('d v r z v z', 'd z z z z z'),\n",
       " ('q l x l s s', 'h s s s s s s'),\n",
       " ('y p t d h v', 'y p t h h v'),\n",
       " ('z y s n t x', 'z d n o o o'),\n",
       " ('f c d n d r', 'f d d d d d'),\n",
       " ('v b j d i m', 'v j m m s m'),\n",
       " ('m i z b v c', 'm i p c c c'),\n",
       " ('h k n k p z', 'x z p p p z'),\n",
       " ('t z d e u n', 't d d u u o'),\n",
       " ('m s p r v f', 'm s f v v f'),\n",
       " ('z v v w e v', 'z e v e e w'),\n",
       " ('n e e z t o', 'n e e t o o'),\n",
       " ('i u d n p j', 'i p p p p o'),\n",
       " ('r h c h p u', 'x h p u p u'),\n",
       " ('k x y z y p', 'k y y y p'),\n",
       " ('q u f g i s', 'q u i i i l'),\n",
       " ('r o p q a q', 'r p a a a q'),\n",
       " ('r b m h m t', 'r m m h m t'),\n",
       " ('f o p k z m', 'f p p k m m'),\n",
       " ('w p s f n u', 'w u u u u u'),\n",
       " ('m b a q o w', 'm a a w o d'),\n",
       " ('h j j n w v', 'h s w w w v'),\n",
       " ('q n o d p u', 'v u y p p u'),\n",
       " ('e l z u u z', 'e z u z u z z'),\n",
       " ('m z e r x q', 'm x e x x q'),\n",
       " ('j d e k p b', 'j p p p p b'),\n",
       " ('j i w w x y', 'j w x x x y w'),\n",
       " ('h f g o x e', 'q f o x x e'),\n",
       " ('y c b c y h', 'y y b h y a'),\n",
       " ('y p s y y l', 't p l y l l'),\n",
       " ('z z z s a a', 'z z z z a a z'),\n",
       " ('i v h e t u', 'i p e u u u'),\n",
       " ('a k e e u i', 'a i u u u i'),\n",
       " ('b l t y l i', 'j i y i i i'),\n",
       " ('x x t u e t', 'w u u w e w w'),\n",
       " ('g p a x h r', 'g a a x h r'),\n",
       " ('z p z s z g', 'z z s s s n'),\n",
       " ('s v t b w y', 's v w w w y'),\n",
       " ('q i v z b q', 'q b x x x x'),\n",
       " ('j d k b y i', 'j i i i y i'),\n",
       " ('f i s x y r', 'o i y x y j'),\n",
       " ('h x v j f e', 'h e f f f e'),\n",
       " ('v b y n k n', 'v a a a a u'),\n",
       " ('b k n q m j', 'b j j j j j'),\n",
       " ('w m f r w s', 'w w s s s s'),\n",
       " ('f v l u j n', 'o q u u j o'),\n",
       " ('k s y q i q', 'k y i q i q'),\n",
       " ('y q r p d z', 'y q r d d z'),\n",
       " ('j d r p n d', 'j l p p l d'),\n",
       " ('c t y e y p', 'c j p p p p'),\n",
       " ('p y m c u j', 'p y c i i i a'),\n",
       " ('b b w a e j', 'b e e i i i'),\n",
       " ('a k f s z r', 'a s s s n r'),\n",
       " ('l x a l u f', 'l u f f f f'),\n",
       " ('e z f w q n', 'e w w w n n'),\n",
       " ('i j m o l n', 'm n n n n n m'),\n",
       " ('n l b n w l', 'n n n n n n n'),\n",
       " ('h r n c h f', 'h f f f f f f'),\n",
       " ('q c s m b n', 'q s s n b n'),\n",
       " ('x y r z x t', 'x r r x t t'),\n",
       " ('s b r d o p', 's d o p p p'),\n",
       " ('o a f w v h', 'o h h h h h'),\n",
       " ('z i z a p t', 'f i a a t t'),\n",
       " ('k h m m d x', 'k h x d d x u'),\n",
       " ('b m k u w s', 'b m u s s s'),\n",
       " ('c p g u w m', 'c w u x w x'),\n",
       " ('v v a v u q', 'v a a l q q v'),\n",
       " ('z t i f x z', 's i i x x'),\n",
       " ('x b b p w a', 'x a a a s a a'),\n",
       " ('w l g p f z', 'w p p f f z'),\n",
       " ('d d c h g b', 'd g g g g b f'),\n",
       " ('k j i k p k', 'k i i k p'),\n",
       " ('r s h y l u', 'r u u u u u'),\n",
       " ('y s f p o m', 'y m m p o m'),\n",
       " ('t n i u x q', 't i q x x q'),\n",
       " ('h a r f u c', 'h r s u u c'),\n",
       " ('t n h h e w', 't h h w w w'),\n",
       " ('r v d n s d', 'r s n s d d'),\n",
       " ('e e i f t l', 'e t t t t a'),\n",
       " ('u p x a e v', 'u e b v v v'),\n",
       " ('q n e l m m', 'e m m m m m'),\n",
       " ('m w l t o u', 'm t l y y y'),\n",
       " ('d i n f c j', 'n f f f c j'),\n",
       " ('h j n w m i', 'h y y y y y'),\n",
       " ('x f n i n p', 'x p p p p p'),\n",
       " ('g h z s i m', 'i i z m i m'),\n",
       " ('r s z n x f', 'r x n n x f'),\n",
       " ('h v k q t x', 't v x x x x'),\n",
       " ('t y t k m v', 't m m m m b'),\n",
       " ('l y i k m t', 'l m h m m h'),\n",
       " ('v z y j q s', 'v j j j q s'),\n",
       " ('m u u j c q', 'm u c c q q'),\n",
       " ('l z c x y l', 'l y c x l l'),\n",
       " ('f c v c g l', 'f b l l l l'),\n",
       " ('a g v t a i', 'a i i a i i'),\n",
       " ('r o g f n v', 'r n f f n a'),\n",
       " ('b s m i n n', 'd n n n n n'),\n",
       " ('q f v y u c', 'q y v c g c'),\n",
       " ('l r i b d e', 'l r b b e e'),\n",
       " ('t j v p c f', 't p v f f f'),\n",
       " ('h m w f j l', 'h f f f l l'),\n",
       " ('w z k w d w', 'w w w w w w'),\n",
       " ('x e d b j k', 'x k b j j k'),\n",
       " ('p o d c s d', 'p c s s s d'),\n",
       " ('b b j v z l', 'b z z z z l'),\n",
       " ('i n t q e s', 'i s s q s s'),\n",
       " ('b h d b l i', 'b l l b l i'),\n",
       " ('w f l d h t', 'w f l d t t'),\n",
       " ('m t t e f z', 'm e e e z l'),\n",
       " ('u u j c q q', 'u u u q q q u'),\n",
       " ('g y t u s f', 'g f f f f f'),\n",
       " ('n v f j v d', 'n j t d d d'),\n",
       " ('w p i r e x', 'w x x x x x'),\n",
       " ('v y d l p q', 'v p p p p q'),\n",
       " ('d c x w h o', 'd m m h o o'),\n",
       " ('s n z s p r', 's y z r r r'),\n",
       " ('m v k x c n', 'm h k p c p'),\n",
       " ('t a f h c o', 't o f o l o'),\n",
       " ('k j f l r o', 'k f o l o o'),\n",
       " ('d u t u q y', 'v e q d d d e'),\n",
       " ('m d a d n w', 'm d a d a w'),\n",
       " ('o c m o q q', 'o q q q q'),\n",
       " ('g j f p o o', 'g j o o o o'),\n",
       " ('d k y b z g', 'd z z b z g'),\n",
       " ('i a p q w q', 'i p p q q q'),\n",
       " ('i w y w s x', 'i x s x x x'),\n",
       " ('a q s o i d', 'o s s o d d'),\n",
       " ('c k j k r w', 'c j j w w w'),\n",
       " ('b a e u u w', 'a u u u u w'),\n",
       " ('d e k x w z', 'd e x z w'),\n",
       " ('a r t p z y', 'a p n p u'),\n",
       " ('d a x b c n', 'd x b b n n'),\n",
       " ('f x f n i i', 'f x i f i i'),\n",
       " ('t q j d d s', 's j d d s s'),\n",
       " ('y p p k f k', 'y a a a f a'),\n",
       " ('g f k i s z', 'i i s i i i i'),\n",
       " ('c r s l s j', 'p j s j j j'),\n",
       " ('d g s v l f', 'd g s f f f'),\n",
       " ('h v d i d m', 'h m x i k'),\n",
       " ('g p i l o z', 's i i o o z'),\n",
       " ('n s r f d h', 'n s h f d h'),\n",
       " ('w f y o p m', 'w f y p m m'),\n",
       " ('b m g a f x', 'b i i i i x i'),\n",
       " ('i r t l e p', 'i l l l e'),\n",
       " ('o r z t p z', 'o z p q p'),\n",
       " ('u b i n p g', 'p g p p p g'),\n",
       " ('v i z t m n', 'v t z t n n'),\n",
       " ('m c h m j d', 'm a h j j d'),\n",
       " ('i w j m t x', 'i w m x x x'),\n",
       " ('k e l s a l', 'k a s a a l'),\n",
       " ('a l w g e b', 'a b b b b b'),\n",
       " ('t v g r r v', 't v o r r v o'),\n",
       " ('s l c h k a', 'w a h a a a'),\n",
       " ('m l f m v e', 'm l f e v e'),\n",
       " ('p z t h q a', 'p t t h q a'),\n",
       " ('t w g o g z', 'n o o z z z'),\n",
       " ('f n v n u z', 'o u u u u o'),\n",
       " ('n m i i a b', 'n a x b a b'),\n",
       " ('p h s h c s', 'o s s s s s'),\n",
       " ('i i m n y p', 'i p p p y p'),\n",
       " ('x r z j n x', 'x r x x x'),\n",
       " ('n h e l d o', 'n o l d d o'),\n",
       " ('k w l v s p', 'd p p s p p'),\n",
       " ('e q r y l w', 'e q y s s s'),\n",
       " ('o p a g g f', 'o i g g f f f'),\n",
       " ('e n h b i b', 'e v b b i b'),\n",
       " ('b u g z g w', 'b z z z t w'),\n",
       " ('i k q u d q', 'i l u u d q'),\n",
       " ('v l o o f l', 'v o o t t x'),\n",
       " ('h k s x n s', 'b n s s n s'),\n",
       " ('k l g i a w', 'k w w w w w'),\n",
       " ('t c h u i s', 't i i i i s'),\n",
       " ('s b j h y d', 's h h d y d'),\n",
       " ('s y q r z e', 's y r r z e'),\n",
       " ('a k z z q o', 'a o o o o o'),\n",
       " ('q i a e z c', 'q i c c c c'),\n",
       " ('o p t f v s', 'o p s s s s'),\n",
       " ('b c c g f f', 't g f f f f j'),\n",
       " ('r r h v q f', 'r v v v f f'),\n",
       " ('i i a q c k', 'i i i o i i'),\n",
       " ('s w i n w i', 's i i w w i'),\n",
       " ('a n z m f t', 'a m m m t t'),\n",
       " ('n t o i n l', 'n l l i l l'),\n",
       " ('g f s b b l', 'g n n b b b a'),\n",
       " ('g p v x q d', 'g q q q d d'),\n",
       " ('x x s t y f', 'x s s t h h x'),\n",
       " ('c e i k n m', 'c a i k m m'),\n",
       " ('q o e o b e', 'q e e y b'),\n",
       " ('b p u e k q', 'f p k e k q'),\n",
       " ('v c h j w q', 'v w h w w q'),\n",
       " ('z e u s y r', 'z s s s y r'),\n",
       " ('b c e a t v', 'f e e a v v'),\n",
       " ('g p a f d j', 'g a j f j j'),\n",
       " ('j b h n c f', 'j h h n c f'),\n",
       " ('e m h m v d', 'e m h d d d p'),\n",
       " ('i o n k w j', 'i h h j j j'),\n",
       " ('b c n x q u', 'b q v u u u'),\n",
       " ('v g v q z t', 'v g v q t t'),\n",
       " ('x z h m l y', 'x m m m y y'),\n",
       " ('p k c c w y', 'p w c y y y k'),\n",
       " ('h a e o g n', 'h a n o n n'),\n",
       " ('n j w g h z', 'n h h z h z'),\n",
       " ('d i j k g o', 'd j j g g o'),\n",
       " ('e s b a c i', 'e a c c c l'),\n",
       " ('h a p l a k', 'a a l l a k'),\n",
       " ('o h k t r f', 'o h k f f f'),\n",
       " ('w k v g r g', 'w k g g o o'),\n",
       " ('s s e t w x', 's x x x w x w'),\n",
       " ('h r k x l f', 'h f x x l f'),\n",
       " ('m b i s q r', 'm s i s q r'),\n",
       " ('u u m c e q', 'u u u c e u u'),\n",
       " ('l k y k c i', 'l z i i i i'),\n",
       " ('f d s c m t', 'f d s m t t'),\n",
       " ('x h x k c a', 'x c a a a a'),\n",
       " ('z r b w m t', 'v m m t t t'),\n",
       " ('a b o h f r', 'a o h f f a'),\n",
       " ('e v n h n s', 'z n n n s s'),\n",
       " ('m w f l f p', 'm p f f p p'),\n",
       " ('w r r u l w', 'w u u u w w'),\n",
       " ('f t a f k y', 'f f a f k'),\n",
       " ('a s l r r o', 'a u u u u u'),\n",
       " ('k c s n a p', 'k p s n p p'),\n",
       " ('w r i v q k', 'w i h v h h'),\n",
       " ('n b k u o v', 'n k v o o v'),\n",
       " ('t v q g o g', 't o o o o g'),\n",
       " ('l x l w u x', 'l u u u u x'),\n",
       " ('b a q n a a', 'b a a a a a a'),\n",
       " ('b z c k m k', 'b k k k k k'),\n",
       " ('a p k q k e', 'a k k q k'),\n",
       " ('r s v r c p', 'r s u u u u'),\n",
       " ('v i f n j f', 'v f f f f f'),\n",
       " ('k w s g r v', 'k w v g v v'),\n",
       " ('i h y a g f', 'i a a f a f'),\n",
       " ('x d y i o k', 'x o i o o k'),\n",
       " ('f d n l l g', 'n l l l g g'),\n",
       " ('a m q x u z', 'a u u u u z'),\n",
       " ('g x k y j u', 'x j f j j u'),\n",
       " ('a a v w z d', 'a d w w z d'),\n",
       " ('l y t p y m', 'l y p p e e'),\n",
       " ('i t c r u j', 'i j i r i j'),\n",
       " ('n v c k f o', 'n f o f o o'),\n",
       " ('x b w p s a', 'x a a s s a'),\n",
       " ('i c p f l n', 'i p f n n n'),\n",
       " ('c z v q b o', 'c b b q b o'),\n",
       " ('v g p s a m', 'v s m m a m'),\n",
       " ('p i j x a u', 'p u u u u u u'),\n",
       " ('n p u y d i', 'n p i i i i'),\n",
       " ('m l v u k e', 'm e v o k e'),\n",
       " ('h l t a e g', 'h e a u e u'),\n",
       " ('m z b s v t', 'm t s v t t'),\n",
       " ('e x c r n j', 'e n j j j j'),\n",
       " ('n z h u k s', 'n o s o s s'),\n",
       " ('q i l r v i', 'q i v i v i'),\n",
       " ('d n x f d y', 'd x x f a a'),\n",
       " ('u f j z c a', 'f f f k a a'),\n",
       " ('g f d x a p', 'g f x j o j'),\n",
       " ('l m f c x n', 'b x x x x n'),\n",
       " ('s j l r q v', 's o o o o o'),\n",
       " ('v x r r z h', 'v a h h h h'),\n",
       " ('u j w a l j', 'u l w a l j u'),\n",
       " ('f m n v p u', 'f p u p u u f'),\n",
       " ('p u e c v m', 'p c t c f a'),\n",
       " ('o b o t v t', 'o o t t t t o'),\n",
       " ('v f x s i w', 'v x x i i t'),\n",
       " ('h z h n h o', 'h o o o o o'),\n",
       " ('s w f u i k', 's f u i i l'),\n",
       " ('q z e q q h', 'q e q q h h'),\n",
       " ('c u p c n f', 'c u f f f f'),\n",
       " ('s a v e b e', 's e o e b'),\n",
       " ('f u r b v l', 'f b b b l l'),\n",
       " ('b o j g v a', 'm a a a a a'),\n",
       " ('w p b d l f', 'u f d f f f'),\n",
       " ('w n k o v k', 'w k k k v k'),\n",
       " ('r j v g v m', 'r m m v m m'),\n",
       " ('w a s f a m', 'w m f f a m'),\n",
       " ('d v t s u f', 'd s s f f f'),\n",
       " ('j z y f k g', 'r g k f k g'),\n",
       " ('i p b g c a', 'i p b a c a'),\n",
       " ('d t u i e p', 'd p p p u'),\n",
       " ('t n y a m q', 't k a a q q'),\n",
       " ('u k u m w k', 'u k k w k k'),\n",
       " ('z m p h f l', 'z m h h f l'),\n",
       " ('z l e k z f', 'z z f k f f z'),\n",
       " ('y y o f o o', 'y o o q q o'),\n",
       " ('z p o m j z', 'z j j t j z'),\n",
       " ('f v q m l v', 'z y l d l d'),\n",
       " ('p o a o x j', 'm o o x j j x'),\n",
       " ('w p n f n g', 'w n u u g g'),\n",
       " ('v y u i q k', 'v f u i k k'),\n",
       " ('z f b a j a', 'z y w j j a'),\n",
       " ('n t k v d k', 'n k k d d u'),\n",
       " ('q l a p t f', 'q e p f f f'),\n",
       " ('y s j t c h', 'y s j t c s'),\n",
       " ('s j e e a r', 's e e r r x'),\n",
       " ('x s d j l l', 'x s d l l'),\n",
       " ('i x k o g t', 'e x r r a t'),\n",
       " ('o j b n a p', 'o n x p p p'),\n",
       " ('e w h m f o', 'e f f o f o'),\n",
       " ('q n s h e d', 'q e d e e d'),\n",
       " ('a a s z w l', 'a a a w w w a'),\n",
       " ('t u v p o l', 't u p p o e'),\n",
       " ('j i x z v w', 'j v x v v w'),\n",
       " ('h m o k g f', 'h w o k g w'),\n",
       " ('h r b a g w', 'h b a g w w'),\n",
       " ('w y a o f p', 'w f a p p p'),\n",
       " ('j g a m p j', 'j a a m j j'),\n",
       " ('d r f e n b', 'd f f e b b'),\n",
       " ('c z t g l j', 'c j j j j j'),\n",
       " ('l f u u l n', 'l u l n n l l'),\n",
       " ('d v k i i d', 'd i i i i d i'),\n",
       " ('m o g v r v', 'm o k v r v o'),\n",
       " ('k u g z p q', 'k u p z y x'),\n",
       " ('b j a z j i', 'b j a i i i'),\n",
       " ('f x e q t e', 'n e e q e e'),\n",
       " ('r j m y i h', 'r i m i i h'),\n",
       " ('c j d s v n', 'u s s s n n'),\n",
       " ('f s d y z w', 'f d y y w w'),\n",
       " ('s x e p g n', 's x a p a n'),\n",
       " ('v g z c h e', 'f h e e h e'),\n",
       " ('w f q l n p', 'w l l l n i'),\n",
       " ('z z r l l n', 'z n n n n n z'),\n",
       " ('n g z h y e', 't h y e y e'),\n",
       " ('t c g e m r', 't m m m m r'),\n",
       " ('l m r i a n', 'f f a a n n'),\n",
       " ('f y z g s u', 'f y g u s u'),\n",
       " ('k i k z b e', 'k i z b b e'),\n",
       " ('a b p k k v', 'a f o f v v'),\n",
       " ('p c o g m o', 'p g o g o o'),\n",
       " ('q x b a p p', 'q b p p p p'),\n",
       " ('q t x g b q', 'q b x g q'),\n",
       " ('n l k d m n', 'n n k n m n'),\n",
       " ('a x c l c d', 'a c c d d d'),\n",
       " ('x i j v q g', 'x f g q g g'),\n",
       " ('l i r h y c', 'l y y c y c'),\n",
       " ('i g x a d s', 'i a a a s s'),\n",
       " ('m f x d q v', 'm f q d h h'),\n",
       " ('s h v g w s', 's s s s s s s'),\n",
       " ('o y w b a z', 'o n n a a z'),\n",
       " ('o p r j t f', 'o j j f f f'),\n",
       " ('u k y p j d', 'u y y j u d'),\n",
       " ('r p w g q a', 'z a a a f a'),\n",
       " ('g i k h e x', 'g i e e e x'),\n",
       " ('n t b r t v', 'n r t v t v'),\n",
       " ('r m t g e c', 'r e e g c c'),\n",
       " ('n k g t d a', 'n k a a a a'),\n",
       " ('v f u e s b', 'v f s s s b'),\n",
       " ('j e n k w o', 'j o o o w o w'),\n",
       " ('e s d j i j', 'i i p p j j'),\n",
       " ('s q a u d d', 's u u u d u'),\n",
       " ('m h v m m p', 'd p p m p p'),\n",
       " ('x j p p t m', 'x p p m m m'),\n",
       " ('l y l t u c', 'l y c t u c l'),\n",
       " ('i v a x h z', 'i a a x z z'),\n",
       " ('g s j d d f', 'g f f d f f'),\n",
       " ('s y k k z h', 's y h z z h'),\n",
       " ('g o s n g o', 'g o n o o o'),\n",
       " ('e w q h c y', 'e w q y y y'),\n",
       " ('e p d h x r', 'i h h h r r'),\n",
       " ('j g k a j q', 'j k a a j j'),\n",
       " ('f q n f k a', 'f a k a a a'),\n",
       " ('w a w j s a', 'w i i i i a'),\n",
       " ('d f h a z c', 'd c p z z c'),\n",
       " ('q u a q m x', 'x a a m m o'),\n",
       " ('t o y v a h', 't a y a a h'),\n",
       " ('s w t p k o', 's w w w o o'),\n",
       " ('n h e g t x', 'n h e x t x'),\n",
       " ('m d x r v i', 'm i i i i i'),\n",
       " ('z r o s k s', 'z s o s s s'),\n",
       " ('l r m i z i', 'a z i i z i'),\n",
       " ('d w w n p q', 'd w p p p p'),\n",
       " ('f j u l t j', 'f j u l j j'),\n",
       " ('s m k h b r', 's h h h b r'),\n",
       " ('d p w k f t', 'd f w f f t'),\n",
       " ('t q l u u r', 'q u u u u u s'),\n",
       " ('y a v m j g', 'y m m j j r x'),\n",
       " ('n m u u m s', 'n u u s s s'),\n",
       " ('n g a b f g', 'a b a b f g'),\n",
       " ('a h i d p l', 'a h p p p l'),\n",
       " ('f o d r l k', 'f z z l l k'),\n",
       " ('n w s p c m', 'a m p p m m'),\n",
       " ('y d x p b c', 'y d p c b c'),\n",
       " ('r s u n h x', 'r u n n h x'),\n",
       " ('z y r z c k', 'z z k z k k'),\n",
       " ('u r o l g s', 'u u l l v v'),\n",
       " ('u s o k l a', 'u s a a a a'),\n",
       " ('a d u b i i', 'a u i i i i'),\n",
       " ('l a l w b o', 'l o o b o o m'),\n",
       " ('n q e p y d', 'n p d p m d'),\n",
       " ('w q q r r o', 'w q o o o o'),\n",
       " ('z e d z j f', 's f f j f f'),\n",
       " ('p f a g s g', 'p p p g g g p'),\n",
       " ('b i b i i i', 's i i i i i i'),\n",
       " ('m v h r u o', 'm h f f o o'),\n",
       " ('l e v d x z', 'l x x x x z'),\n",
       " ('f j p p w n', 'f p p n n n'),\n",
       " ('e r x e r o', 'e r o o o o'),\n",
       " ('i b v x i q', 'n s i i i s'),\n",
       " ('w l p r p k', 'w p p p k k'),\n",
       " ('j s m v w m', 'j s v v n n'),\n",
       " ('z r j h h r', 'a w h r h r'),\n",
       " ('d m v z z c', 'd z z z z c'),\n",
       " ('r t f j h z', 'r j j j h z'),\n",
       " ('r a v x b b', 'r x b b b b'),\n",
       " ('e f d x x u', 'e q u u u u'),\n",
       " ('a q s g o j', 'a s o o o s'),\n",
       " ('g i r d w w', 'g u u u u k'),\n",
       " ('p s b r a b', 'p b b b a d'),\n",
       " ('h g b z d a', 'h d b z d a'),\n",
       " ('p c z l g f', 'b f f f f f'),\n",
       " ('q r l f a o', 'q o x a a o'),\n",
       " ('q p z g h d', 'q z d d h d'),\n",
       " ('f a f n m c', 'r f f n c c'),\n",
       " ('o r k z y y', 'o y y y y y'),\n",
       " ('p w m x a i', 'p a a x a i'),\n",
       " ('s o c i z y', 's y y x y y'),\n",
       " ('g m e k b c', 'g f k b b c'),\n",
       " ('p i v a h h', 'p h a h h h'),\n",
       " ('g u d f w t', 'g f f f x t'),\n",
       " ('l g g x i p', 'l g w w p p'),\n",
       " ('b j b v s f', 'b f f f f f'),\n",
       " ('j k y x h y', 'w x x x h y y'),\n",
       " ('r n w v y r', 'r n w v y r'),\n",
       " ('s z t g s g', 'y z t g x x'),\n",
       " ('g l e k n w', 'f w k k k w'),\n",
       " ('v o j q v b', 'v o j b b b'),\n",
       " ('c l n m w o', 'c l o o w o'),\n",
       " ('f w z b r d', 'f d d d d d'),\n",
       " ('z e f o q k', 'z f o o k'),\n",
       " ('q a j g w y', 'a a y g w y'),\n",
       " ('u p x z y k', 'u x x h k k'),\n",
       " ('j h q y k d', 'j k k k k d'),\n",
       " ('p c w a r v', 'p v r v r v'),\n",
       " ('q x t h b m', 'w x h m m f'),\n",
       " ('l k i j d h', 'l d i d h h'),\n",
       " ('c p o v l l', 'c o o l l l'),\n",
       " ('l x y o d g', 'l o o o g g'),\n",
       " ('a w y y p m', 'a y y p m a'),\n",
       " ('x m m i p i', 'x u q q c q'),\n",
       " ('w i p e g e', 'w g x e e e'),\n",
       " ('n p z m b c', 'n n n n n c'),\n",
       " ('o w q h g z', 'v w h h g z'),\n",
       " ('y i u i q x', 'y i n x x x'),\n",
       " ('y l e q w g', 'o e g g g g'),\n",
       " ('q z m p p v', 'q m x p u v'),\n",
       " ('d n l q j y', 'd j j j j y'),\n",
       " ('r f q h k k', 'r k k k k k k'),\n",
       " ('w b c q p o', 'w q p q p o'),\n",
       " ('y f q x p c', 'y f p c c c'),\n",
       " ('x o o n f y', 'x f y y f y'),\n",
       " ('c x n w k w', 'h k j w j j'),\n",
       " ('r f k i w g', 'f f k i w g'),\n",
       " ('t g k l v h', 'd p l l p d'),\n",
       " ('r w f m h g', 'r f f h h g'),\n",
       " ('q n g a q c', 'q a a a c c'),\n",
       " ('y f j t t v', 'y v v v v v'),\n",
       " ('i a d a u g', 'i a u u u i'),\n",
       " ('d b j v p f', 'd j j f f f'),\n",
       " ('k a l j a p', 'k a j p p p'),\n",
       " ('m v g d w t', 'm v d d t t'),\n",
       " ('r d r a f v', 'r a f a f v'),\n",
       " ('m r m i l k', 'm i i i l k'),\n",
       " ('y z o g l p', 'y o x l p p'),\n",
       " ('b g x o q r', 'b o o o r r'),\n",
       " ('l k e h x p', 'k h h h p p'),\n",
       " ('g x f v y m', 'g v y y y p'),\n",
       " ('j a l c g i', 'a i i i i i'),\n",
       " ('g w w m z t', 'i w m m t t'),\n",
       " ('b f r f c w', 'b f f f d w f'),\n",
       " ('w g v f e m', 'w m m e m m'),\n",
       " ('v p b k s e', 'v s s k s e'),\n",
       " ('d q z j t o', 'd j j j o o'),\n",
       " ('y g m q r i', 'y z h h r h'),\n",
       " ('i n c f k y', 'b n k f k y'),\n",
       " ('v c d m n y', 'v c d m u y'),\n",
       " ('c w t s i m', 'c s s s i m'),\n",
       " ('m s h i y g', 'm d d d y g'),\n",
       " ('m q o r k e', 'm r h e h e'),\n",
       " ('t p h i c w', 'v p i i w w'),\n",
       " ('b x g m z w', 'e w g z w w'),\n",
       " ('k x g e g f', 'k e e f f f x'),\n",
       " ('u p h h a j', 'u h h j j j'),\n",
       " ('d i p b q p', 'd p p p p p'),\n",
       " ('k q u m j w', 'c w w w j w'),\n",
       " ('o m l n r l', 'o m l n r g'),\n",
       " ('d i w n b t', 'd i t t t t'),\n",
       " ('b p x n i l', 'x l i i i l'),\n",
       " ('l h h r j m', 'l h j j j m'),\n",
       " ('t p b q f v', 't p f f f v'),\n",
       " ('e e o a s h', 'e h h h h h'),\n",
       " ('b z v q h t', 'b q v q t t'),\n",
       " ('f o z u y e', 'f o u m m m'),\n",
       " ('h c e x y b', 'h y y x y b'),\n",
       " ('o c d o t r', 'o o d s r f'),\n",
       " ('q l m b p b', 'q w b b w b'),\n",
       " ('a o l c m n', 'a n n n n n'),\n",
       " ('v b k j s w', 'v s s s s w'),\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
