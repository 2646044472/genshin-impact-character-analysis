{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a82f151-46a4-4dfb-bc57-faad10e39668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb48a7a8-e5b9-4829-b95d-e32806607d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2859, 0.2315, 0.6125, 0.0917, 0.7203, 0.0546]),\n",
       " tensor([0.2401, 0.0420, 0.1979, 0.5013, 0.8952, 0.0941]),\n",
       " tensor([0.9257, 0.1764, 0.6721, 0.2044, 0.1741, 0.3446])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(6)\n",
    "b = torch.rand(6)\n",
    "c = torch.rand(6)\n",
    "[a, b, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7044c0-7753-4031-a697-1e08b8781bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([a, b, c],\"model/tensor_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee66fc7-5d68-4d57-bead-ac80ae2168ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2859, 0.2315, 0.6125, 0.0917, 0.7203, 0.0546]),\n",
       " tensor([0.2401, 0.0420, 0.1979, 0.5013, 0.8952, 0.0941]),\n",
       " tensor([0.9257, 0.1764, 0.6721, 0.2044, 0.1741, 0.3446])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"model/tensor_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a862d6a7-40a3-4b3e-a3fd-b088bf373130",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dict = {'a':a, 'b':b, 'c':c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9075ca90-dc10-4922-a711-8f4d678bc627",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensor_dict,\"model/tensor_dict_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0912117-aa04-46c1-bf7f-829087ec4160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([0.2859, 0.2315, 0.6125, 0.0917, 0.7203, 0.0546]),\n",
       " 'b': tensor([0.2401, 0.0420, 0.1979, 0.5013, 0.8952, 0.0941]),\n",
       " 'c': tensor([0.9257, 0.1764, 0.6721, 0.2044, 0.1741, 0.3446])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"model/tensor_dict_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017487fe-df42-4827-9d14-e744c840bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0fc5b-4817-4a42-b82b-c7835e3ebddd",
   "metadata": {},
   "source": [
    "### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb61bd7d-3594-4672-93f2-345e20c097dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "input_size = 28*28\n",
    "hidden_size = 512\n",
    "num_classes = 10\n",
    "model = MLP(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f0e898-bce0-48c4-ac40-47ec652f5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model/mlp_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463aeaff-3ce2-446b-bca9-bd39f9aecc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_state_dict = torch.load(\"model/mlp_state_dict.pth\")\n",
    "model = MLP(input_size,hidden_size,num_classes)\n",
    "model.load_state_dict(mlp_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c85190-5241-46e1-95ad-51e5a2f22501",
   "metadata": {},
   "source": [
    "### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ccf53e0-77c0-42de-b0da-1e2e3d451bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model/mlp_model.pth\")\n",
    "mlp_load = torch.load(\"model/mlp_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76defa-dfa0-4ceb-a9f9-195732137acc",
   "metadata": {},
   "source": [
    "Cons: Relative paths: If the working directory changes, the relative path \"model/mlp_model.pth\" might not point to the correct location, leading to FileNotFoundError when loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d9277-1439-4bab-8f31-b7abaf29bca0",
   "metadata": {},
   "source": [
    "### method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f517ad3d-8bb3-4894-8f08-a92c1d87d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "loss = 0.01\n",
    "PATH = \"model/model_checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d2809e-e441-4ccc-9ffc-dfd7a3beca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "}, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2799e2b6-a516-4136-ba1a-f6065728d357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "model = MLP(input_size,hidden_size,num_classes)\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
